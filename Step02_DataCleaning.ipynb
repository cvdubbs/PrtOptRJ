{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6fee7d5",
   "metadata": {},
   "source": [
    "In this second step we'll be cleaning weekly_returns from the issues we found in the data validations steps.\n",
    "\n",
    "We could create a dictionary or new dataframe with all the missing values and then merge it into the current dataframe but given the low amount of data needed to be added we can also just .loc it in with negative indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6f6100a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  ticker_id  weekly_return\n",
      "0   5/6/2011          0      -3.500018\n",
      "1  5/13/2011          0      -2.756460\n",
      "2  5/20/2011          0       0.319715\n",
      "3  5/27/2011          0       1.444635\n",
      "4   6/3/2011          0       0.251305\n",
      "5  6/10/2011          0      -2.924585\n",
      "6  6/17/2011          0      -1.463312\n",
      "7  6/24/2011          0       0.373256\n",
      "8   7/1/2011          0       5.846155\n",
      "9   7/8/2011          0      -0.477576\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3654 entries, 0 to 3654\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           3654 non-null   object \n",
      " 1   ticker_id      3654 non-null   int64  \n",
      " 2   weekly_return  3654 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 114.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "weeklyreturnsdf = pd.read_csv('DataSets/weekly_returns.csv')\n",
    "tickerattridf = pd.read_csv('DataSets/ticker_attributes.csv')\n",
    "\n",
    "weeklyreturnsdf.loc[-4] = ['5/6/2011', 0, -3.500018]\n",
    "weeklyreturnsdf.loc[-3] = ['5/13/2011', 0, -2.756460]\n",
    "weeklyreturnsdf.loc[-2] = ['5/20/2011', 0, 0.319715]\n",
    "weeklyreturnsdf.loc[-1] = ['5/27/2011', 0, 1.444635]\n",
    "weeklyreturnsdf.loc[3650] = ['4/30/2021', 6, 0.023186]\n",
    "weeklyreturnsdf.index = weeklyreturnsdf.index + 4  # shifting index\n",
    "weeklyreturnsdf = weeklyreturnsdf.sort_index()  # sorting by index\n",
    "\n",
    "print(weeklyreturnsdf.head(n=10))\n",
    "print(\"\\n\")\n",
    "print(weeklyreturnsdf.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad8fb05",
   "metadata": {},
   "source": [
    "Now we just replace the -100% from ticker 4 on 5/10/2019 with  0.304620\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee2b6e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  ticker_id  weekly_return\n",
      "2506  5/10/2019          4        0.30462\n",
      "\n",
      "\n",
      "         ticker_id  weekly_return\n",
      "count  3654.000000    3654.000000\n",
      "mean      3.000000       0.151485\n",
      "std       2.000274       2.205844\n",
      "min       0.000000     -16.636300\n",
      "25%       1.000000      -0.420158\n",
      "50%       3.000000       0.074637\n",
      "75%       5.000000       0.811958\n",
      "max       6.000000      44.000000\n",
      "\n",
      "\n",
      "          Minimum_Date Maximum_Date\n",
      "ticker_id                          \n",
      "0           2011-05-06   2021-04-30\n",
      "1           2011-05-06   2021-04-30\n",
      "2           2011-05-06   2021-04-30\n",
      "3           2011-05-06   2021-04-30\n",
      "4           2011-05-06   2021-04-30\n",
      "5           2011-05-06   2021-04-30\n",
      "6           2011-05-06   2021-04-30\n"
     ]
    }
   ],
   "source": [
    "weeklyreturnsdf.loc[((weeklyreturnsdf.date == '5/10/2019') & (weeklyreturnsdf.ticker_id == 4)),'weekly_return']=0.304620\n",
    "print(weeklyreturnsdf.loc[((weeklyreturnsdf.date == '5/10/2019') & (weeklyreturnsdf.ticker_id == 4))])\n",
    "print(\"\\n\")\n",
    "print(weeklyreturnsdf.describe())\n",
    "print(\"\\n\")\n",
    "\n",
    "weeklyreturnsdf['date'] =  pd.to_datetime(weeklyreturnsdf['date'], format='%m/%d/%Y')\n",
    "tickerdatesdf = weeklyreturnsdf.groupby(['ticker_id'])\n",
    "tickerdatesdf2 = tickerdatesdf.agg(Minimum_Date=('date', np.min), Maximum_Date=('date', np.max))\n",
    "print(tickerdatesdf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002ad52d",
   "metadata": {},
   "source": [
    "in order to better use this data set we're also going to move ticker_id's to their stock tickers and move them to columns so we can use our dates as an index in future dataframes. We're also going to divide all of the returns by 100 in order to return them to a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "351e3c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker           AGG       EEM       EFA       IJR       JNK       SHY  \\\n",
      "date                                                                     \n",
      "2011-05-06  0.004848 -0.035000 -0.029310 -0.030733  0.001847  0.001024   \n",
      "2011-05-13  0.001219 -0.027565 -0.016071  0.007927 -0.002210  0.000475   \n",
      "2011-05-20  0.001873  0.003197 -0.002145 -0.008949  0.004430  0.000594   \n",
      "2011-05-27  0.004113  0.014446  0.005291  0.008893 -0.000980  0.001543   \n",
      "2011-06-03  0.001887  0.002513  0.002138 -0.032818 -0.011500  0.000427   \n",
      "...              ...       ...       ...       ...       ...       ...   \n",
      "2021-04-01  0.002653  0.011076  0.003394  0.007320  0.004751 -0.000587   \n",
      "2021-04-09  0.001228 -0.005756  0.014702 -0.005268  0.002301  0.000116   \n",
      "2021-04-16  0.003153  0.014939  0.016669  0.011506  0.001010  0.000232   \n",
      "2021-04-23  0.001833  0.005152 -0.002775  0.001264  0.001101  0.000000   \n",
      "2021-04-30 -0.002266 -0.011898 -0.012141 -0.003336  0.000825  0.000232   \n",
      "\n",
      "ticker           SPY  \n",
      "date                  \n",
      "2011-05-06 -0.016345  \n",
      "2011-05-13 -0.001192  \n",
      "2011-05-20 -0.003208  \n",
      "2011-05-27 -0.000749  \n",
      "2011-06-03 -0.023144  \n",
      "...              ...  \n",
      "2021-04-01  0.011692  \n",
      "2021-04-09  0.027159  \n",
      "2021-04-16  0.014022  \n",
      "2021-04-23 -0.001246  \n",
      "2021-04-30  0.001344  \n",
      "\n",
      "[522 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "weeklyreturnsdf = pd.merge(weeklyreturnsdf,tickerattridf[['ticker_id','ticker']],on='ticker_id', how='left')\n",
    "weeklyreturnsdf = weeklyreturnsdf.drop(columns=['ticker_id'])\n",
    "weeklyreturnsdf = pd.pivot_table(weeklyreturnsdf, values='weekly_return', index=['date'],\n",
    "                    columns=['ticker'])\n",
    "weeklyreturnsdf = weeklyreturnsdf.div(100)\n",
    "print(weeklyreturnsdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88ea385",
   "metadata": {},
   "source": [
    "Now that the data has been cleaned, is logical, and aligns on dates we can output this dataframe to a clean .csv file for our portfolio optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a6b68fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "weeklyreturnsdf.to_csv(\"DataSets/weekly_returns_clean.csv\",index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
