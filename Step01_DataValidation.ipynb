{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5501af74",
   "metadata": {},
   "source": [
    "The first step for this project (and almost every project) is pull the data and validating it. Here, no sql queries are nessescary as the csv files have been provided. So the next step is validating and cleaning our data sets.\n",
    "\n",
    "There's two data sets to validate, weekly_returns.csv and ticker_attributes.csv. \n",
    "\n",
    "Let's start by loading them into dataframes and taking a quick look via head and tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afd08bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3649 entries, 0 to 3648\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   date           3649 non-null   object \n",
      " 1   ticker_id      3649 non-null   int64  \n",
      " 2   weekly_return  3649 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 85.6+ KB\n",
      "None\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   ticker_id    7 non-null      int64 \n",
      " 1   ticker       7 non-null      object\n",
      " 2   description  7 non-null      object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 296.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "weeklyreturnsdf = pd.read_csv('DataSets/weekly_returns.csv')\n",
    "tickerattridf = pd.read_csv('DataSets/ticker_attributes.csv')\n",
    "\n",
    "print(weeklyreturnsdf.info())\n",
    "print(\"\\n\")\n",
    "print(tickerattridf.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18817a9a",
   "metadata": {},
   "source": [
    "The data set for ticker attributes is small enough to validate completely by just printing it. \n",
    "\n",
    "There's no issues with blank or missing data that we can see from checking Non-Null Count. The column ticker_id matches data type in both datasets so we'll be using that as our foreign key whenever we join the sets for summary. \n",
    "\n",
    "Date is Dtype object by default not datetime or datetime64[ns] which isn't an issue right now, but will need to be addressed in future loads of the csv (including  parse_dates=['date'] in future read_csv's)\n",
    "\n",
    "Next we'll look at a sample of the data, min and max based on key fields and check for duplicates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29ca19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  ticker_id  weekly_return\n",
      "0   6/3/2011          0       0.251305\n",
      "1  6/10/2011          0      -2.924585\n",
      "2  6/17/2011          0      -1.463312\n",
      "3  6/24/2011          0       0.373256\n",
      "4   7/1/2011          0       5.846155\n",
      "\n",
      "\n",
      "   ticker_id ticker                                  description\n",
      "0          0    EEM            iShares MSCI Emerging Markets ETF\n",
      "1          1    EFA                        iShares MSCI EAFE ETF\n",
      "2          2    IJR               iShares Core S&P Small Cap ETF\n",
      "3          3    SPY                       SPDR S&P 500 ETF Trust\n",
      "4          4    AGG         iShares Core U.S. Aggregate Bond ETF\n",
      "5          5    JNK  SPDR Bloomberg Barclays High Yield Bond ETF\n",
      "6          6    SHY           iShares 1-3 Year Treasury Bond ETF\n"
     ]
    }
   ],
   "source": [
    "print(weeklyreturnsdf.head())\n",
    "print(\"\\n\")\n",
    "print(tickerattridf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c78f14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ticker_id  weekly_return\n",
      "count  3649.000000    3649.000000\n",
      "mean      3.002466       0.125429\n",
      "std       1.998559       2.759498\n",
      "min       0.000000    -100.000000\n",
      "25%       1.000000      -0.420284\n",
      "50%       3.000000       0.073433\n",
      "75%       5.000000       0.812018\n",
      "max       6.000000      44.000000\n"
     ]
    }
   ],
   "source": [
    "print(weeklyreturnsdf[[\"ticker_id\",\"weekly_return\"]].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4a1def",
   "metadata": {},
   "source": [
    "So, we do have to handle the issue of when the weekly return is -100%. How often do these extremes occur and are they valid data points?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a08e18da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  ticker_id  weekly_return\n",
      "2502  5/10/2019          4    -100.000000\n",
      "1502  3/13/2020          2     -16.636300\n",
      "1503  3/20/2020          2     -16.308004\n",
      "2025  3/20/2020          3     -14.523411\n",
      "980   3/13/2020          1     -14.315790\n"
     ]
    }
   ],
   "source": [
    "sortedwrdf = weeklyreturnsdf.sort_values(by=['weekly_return'], ascending=True)\n",
    "print(sortedwrdf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b14830",
   "metadata": {},
   "source": [
    "looking at finance.yahoo.com we can get a much more reasonable value for ticket_id 4, AGG. While not exact, it does line up closely (within 3 decimal points).\n",
    "\n",
    "| Date    |  Adjusted Close    | Weekly Return |\n",
    "| ------- | ------------------ | ------------- |\n",
    "| 4/26/19 |           103.1823 | 0.480623      |\n",
    "| 5/3/19  |           103.0779 | -0.101159     |\n",
    "| 5/10/19 |           103.3919 | 0.304620      |\n",
    "| 5/17/19 |           103.7344 | 0.331262      |\n",
    "| 5/24/19 |           104.0959 | 0.348512      |\n",
    "\n",
    "compared to the provided dataset\n",
    "\n",
    "| date    | ticker id  | weekly return  |\n",
    "| ------- | ---------- | -------------- |\n",
    "| 4/26/19 | 4          | 0.480628       |\n",
    "| 5/3/19  | 4          | -0.1008987     |\n",
    "| 5/10/19 | 4          | -100           |\n",
    "| 5/17/19 | 4          | 0.33128262     |\n",
    "| 5/24/19 | 4          | 0.3485322      |\n",
    "\n",
    "So in Data Cleaning We'll replace -100 with 0.304620.\n",
    "\n",
    "We still need to check for duplicates, missing dates, or date misalignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4869999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [date, ticker_id, weekly_return]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "duplicateRowsDF =weeklyreturnsdf[weeklyreturnsdf.duplicated(subset=['date','ticker_id'])]\n",
    "print(duplicateRowsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "908030eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Minimum_Date Maximum_Date\n",
      "ticker_id                          \n",
      "0           2011-06-03   2021-04-30\n",
      "1           2011-05-06   2021-04-30\n",
      "2           2011-05-06   2021-04-30\n",
      "3           2011-05-06   2021-04-30\n",
      "4           2011-05-06   2021-04-30\n",
      "5           2011-05-06   2021-04-30\n",
      "6           2011-05-06   2021-04-23\n"
     ]
    }
   ],
   "source": [
    "weeklyreturnsdf['date'] =  pd.to_datetime(weeklyreturnsdf['date'], format='%m/%d/%Y')\n",
    "tickerdatesdf = weeklyreturnsdf.groupby(['ticker_id'])\n",
    "tickerdatesdf2 = tickerdatesdf.agg(Minimum_Date=('date', np.min), Maximum_Date=('date', np.max))\n",
    "print(tickerdatesdf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0836986d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  weekly_return\n",
      "ticker_id                     \n",
      "0           518            518\n",
      "1           522            522\n",
      "2           522            522\n",
      "3           522            522\n",
      "4           522            522\n",
      "5           522            522\n",
      "6           521            521\n"
     ]
    }
   ],
   "source": [
    "tickerdatesdf3 = tickerdatesdf.agg('count')\n",
    "print(tickerdatesdf3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928a6607",
   "metadata": {},
   "source": [
    "These counts match the missing date information. With the same apporoach we took to fixing the -100 weekly return we'll take to adding in the missing information.\n",
    "\n",
    "for EEM\n",
    "\n",
    "| Date    | Adj Close | Weekly Returns |\n",
    "| ------- | --------- | -------------- |\n",
    "| 4/29/11 | 40.355591 |                |\n",
    "| 5/6/11  | 38.943138 | -3.500018      |\n",
    "| 5/13/11 | 37.869686 | -2.756460      |\n",
    "| 5/20/11 | 37.990761 | 0.319715       |\n",
    "| 5/27/11 | 38.539589 | 1.444635       |\n",
    "| 6/3/11  | 38.636452 | 0.251334       |\n",
    "\n",
    "and the 6/3/11 calculated weekly return approxiamtely matches our data set\n",
    "\n",
    "| date   | ticker_id  | weekly_return  |\n",
    "| ------ | ---------- | -------------- |\n",
    "| 6/3/11 | 0          | 0.2513051      |\n",
    "\n",
    "Now we just need to get our missing week for SHY\n",
    "\n",
    "| Date    | Adj Close | Weekly Returns |\n",
    "| ------- | --------- | -------------- |\n",
    "| 4/23/21 | 86.211014 | 0.000000%      |\n",
    "| 4/30/21 | 86.231003 | 0.023186%      |\n",
    "\n",
    "and the 4/23/21 calculated weekly return approxiamtely matches our data set\n",
    "\n",
    "| date    | ticker_id  | weekly_return  |\n",
    "| ------- | ---------- | -------------- |\n",
    "| 4/23/21 | 6          | 0              |\n",
    "\n",
    "\n",
    "For our next step we'll implement these changes in the data cleaning steps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
